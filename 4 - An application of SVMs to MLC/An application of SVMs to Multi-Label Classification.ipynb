{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" align=\"left\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png\" /></a>&nbsp;| Luca Mossina and [Emmanuel Rachelson](https://personnel.isae-supaero.fr/emmanuel-rachelson?lang=en) | <a href=\"https://supaerodatascience.github.io/machine-learning/\">https://supaerodatascience.github.io/machine-learning/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f04d09ee-0e3c-4a24-b3ce-345323c1ce23"
    }
   },
   "source": [
    "<div style=\"font-size:22pt; line-height:25pt; font-weight:bold; text-align:center;\">An application of SVMs in Multi-Label Classification (MLC)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll see an application which is both harder and less common than binary classification, that of **multi-label classification** (MLC).  \n",
    "Given a list of possible labels, the problem consists in finding one **or more** labels associated to a data point.  \n",
    "For instance, imagine extracting the key topics from a newspaper article, or classifing the elements composing an image. Possibly many labels can be associated to each item.\n",
    "\n",
    "Given a set of labels $\\mathcal{L} = \\{l_1, l_2, ..., l_k\\} \\in \\{0,1\\}^k$, we want to map elements of a feature space $\\mathcal{X}$ to a subset of $\\mathcal{L}$:  \n",
    "\n",
    "$$h : \\mathcal{X} \\longrightarrow \\mathcal{P}(\\mathcal{L})$$\n",
    "\n",
    "The two typical approaches for such problems are known as **Binary Relevance** (BR) and **Label Powerset** (LP).  \n",
    "\n",
    " - BR: each label in $\\mathcal{L}$ is a binary classification problem, $h_{i} : \\mathcal{X} \\longrightarrow l_{i}, l_{i} \\in \\{0,1\\}, i = 1, ..., |\\mathcal{L}|$.  \n",
    " This method ignores any correlation between labels (supposes them independent).\n",
    "\n",
    " - LP: transforms a problem of MLC into one of multiclass classification, mapping elements $x \\in \\mathcal{X}$ directly to $s \\in \\mathcal{P}(\\mathcal{L})$.  \n",
    " This method becomes rapidly inapplicable as the number of elemnts in $\\mathcal{P}(\\mathcal{L})$ grows exponentially with the number of labels.\n",
    " \n",
    "If you are curious on the topic of MLC, you are encouraged to read these references:  \n",
    "J. Read, P. Reutemann, B. Pfahringer, and Geoff Holmes. **MEKA: A multi-label/multi-target extension to Weka**. Journal of Machine Learning Research, 17(21):1-5, 2016.  \n",
    "G. Tsoumakas and I. Katakis. **Multi-label classification: An overview**. International Journal on Data Warehousing and Mining, 3(3):1-13, 2007.  \n",
    "G. Tsoumakas, I. Katakis, and I. Vlahavas. **Mining multi-label data**. Data mining and knowledge discovery handbook, pages 667-685. Springer, 2010.\n",
    " \n",
    "Many other variations exist, but for today we'll focus on BR, the most straightforward to implement. What we will start implementing below is a good start if you want to explore what is done in:  \n",
    "J. Read, B. Pfahringer, G. Holmes, and E. Frank. **Classifier chains for multi-label classification**. Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 254-269, 2009.\n",
    "\n",
    "The equivalent approach for LP is found in:  \n",
    "G. Tsoumakas, I. Katakis, and I. Vlahavas. **Random k-labelsets for multi-label classification**. IEEE Transactions on Knowledge and Data Engineering, 23(7):1079-1089, 2011."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we will use a biology dataset from [Elisseeff and Weston 2001]: this dataset contains micro-array expressions and phylogenetic profiles for 2417 yeast genes. Each gene is annotated with a subset of 14 functional categories (e.g. metabolism, energy, etc.) of the top level of the functional catalogue.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Exercice**<br>\n",
    "<ul>\n",
    "\n",
    "<li> find a suitable package to load the file at `yeast.arff`.  <br>\n",
    "    Hint: <a href=https://docs.scipy.org/doc/scipy/reference/io.html>scipy.io</a> and _read the doc_.<br>\n",
    "<li> Store the data in a pandas dataframe.<br>\n",
    "    Hint: columns of classes will be encoded as 'utf-8', we need integers, look for 'str.decode('utf-8')'\n",
    "<li> check dataset: you should have 2417 samples $\\times$ 117 columns (103 features + 14 labels)\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrows: 2417\n",
      "ncols: 117\n",
      "<class 'numpy.int32'>\n",
      "<class 'numpy.float64'>\n",
      "dataframe dimensions: (2417, 117)\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/code1.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "# Read arff data\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load yeast.arff via dedicated scipy.io function\n",
    "raw_data, metadata = arff.loadarff('../data/yeast/yeast.arff')\n",
    "print(\"nrows:\", len(raw_data))    # 2417\n",
    "print(\"ncols:\", len(raw_data[0])) #  117\n",
    "\n",
    "# Data to pandas, converting unicode columns to integers\n",
    "df = pd.DataFrame(raw_data)\n",
    "# print(df.shape)           # -> (2417, 117)\n",
    "# print(df.head(5))         # for free, we get column names\n",
    "# print(type(df.iloc[0,0])) # -> <class 'bytes'> ## we want to have plain {0,1} integers\n",
    "\n",
    "classes_list = [name for name in df.columns if \"Class\" in name]\n",
    "# print(classes_list)  # -> ['Class1', 'Class2', ... , 'Class14']\n",
    "\n",
    "for col in df[classes_list]:\n",
    "    df[col] = (df[col].str.decode('utf-8').astype(int))\n",
    "\n",
    "print(type(df.iloc[0,0]))  # -> int: as expected\n",
    "print(type(df.iloc[0,15])) # -> float: as expected\n",
    "print(\"dataframe dimensions:\", df.shape)    # -> (2417, 117)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Exercice**<br>\n",
    "<ul>\n",
    "<li> Manually, fit a SVM classifier for each label in the dataset\n",
    "<li> Apply a cross-validation of 60 âˆ• 40: 60% of datapoints to train the model, 40% to test it  <br>\n",
    "   Remember: it is good practice to <b>randomly shuffle</b> the data, in case the data are ordered w.r.t. some data-dependent criterion.\n",
    "<li> Report some performance measure\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/code2.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "# === Hints:\n",
    "CVRATIO = 0.4\n",
    "\n",
    "# === Solution:\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get a list of all features: \"Att1\" ... \"Att103\"\n",
    "features_list = [name for name in df.columns if \"Att\" in name]\n",
    "\n",
    "# Shuffle rows\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# Shown classifier n.1. To you to put it in a nice for loop and store the results\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[features_list],\n",
    "    df[classes_list],\n",
    "    test_size=0.4,\n",
    "    random_state=0 # <- random seed, could be useful to replicate previous results\n",
    ")\n",
    "\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(X_train, y_train[\"Class1\"])\n",
    "\n",
    "y_pred_01 = clf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations**, you reached the end of the practice session! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
